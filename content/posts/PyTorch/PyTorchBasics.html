---
title: "PyTorch basics"
author: "Fan Yin"
date: "2/8/2022"
output: html_document
---



<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML.js"></script>
<p>Wants to be a cool kid in data science? Letâ€™s begin studying DEEP LEARNING by picking up some basic commands in PyTorch. Unfortunately, due to some errors encountered while installing the torch library, I shall not run the codes in this file.</p>
<!-- Again, thanks to brilliant R package reticulate, I am able to run Python codes in R and write this blog comfortably using R markdown. -->
<div id="preparing-the-environment" class="section level2">
<h2>Preparing the environment</h2>
<div id="loading-required-r-libraries" class="section level3">
<h3>Loading required R libraries</h3>
<pre class="r"><code>ipak &lt;- function(pkg){
  new.pkg &lt;- pkg[!(pkg %in% installed.packages()[, &quot;Package&quot;])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  try(sapply(pkg, require, character.only = TRUE), silent = TRUE)
}
packages &lt;- c(&quot;reticulate&quot;)
ipak(packages)</code></pre>
<pre><code>## Warning: package &#39;reticulate&#39; was built under R version 4.1.2</code></pre>
<pre><code>## reticulate 
##       TRUE</code></pre>
</div>
<div id="set-up-the-r-python-environment" class="section level3">
<h3>Set up the R-Python environment</h3>
<pre class="r"><code>library(reticulate)
# use_python(Sys.which(&quot;python&quot;))
# use_condaenv(&quot;py3.7&quot;, required = TRUE)
use_condaenv(&quot;r-reticulate&quot;)</code></pre>
</div>
<div id="install-required-python-libraries" class="section level3">
<h3>Install required Python libraries</h3>
<pre class="r"><code>py_install(&quot;pandas&quot;) # install pandas if it is not available
py_install(&quot;numpy&quot;)
py_install(&quot;torch&quot;)</code></pre>
</div>
<div id="import-required-python-libraries" class="section level3">
<h3>Import required Python libraries</h3>
<pre class="python"><code>import pandas as pd
import numpy as np
import torch</code></pre>
</div>
</div>
<div id="tensor" class="section level2">
<h2>Tensor</h2>
<div id="creating-tensor-from-python-lists" class="section level3">
<h3>Creating tensor from Python lists</h3>
<pre class="python"><code>points = torch.zeros(6)
points = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 5.0]])</code></pre>
</div>
<div id="tensor-storage" class="section level3">
<h3>Tensor storage</h3>
<pre class="python"><code>points = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 5.0]])
points_storage = points.storage()
# changeing the value of a storage changes the content of its referring tensor
points_storage[0] = 100.0
print(points)</code></pre>
</div>
<div id="indexing-tensors" class="section level3">
<h3>Indexing tensors</h3>
<pre class="python"><code>points = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 5.0]])
#
points[1:] # all rows after first
points[1:,:] # all rows after first, all columns
points[1:,0] # all rows after first, first column
# convert to numpy
points_np = points.numpy()
# obtain a pytorch tensor from a numpy array
points = torch.from_numpy(points_np)</code></pre>
</div>
<div id="saving-tensor" class="section level3">
<h3>Saving tensor</h3>
<pre class="python"><code># 
torch.save(points, &quot;./mypoints.t&quot;)
#
with open(&quot;./mypoints2.t&quot;, &quot;wb&quot;) as f:
torch.save(points, f)
# 
with open(&quot;./mypoints2.t&quot;, &quot;wb&quot;) as f:
points = torch.load(f)</code></pre>
</div>
</div>
<div id="regression-analysis-with-pytorch" class="section level2">
<h2>Regression analysis with PyTorch</h2>
<p>We first generate data as follows</p>
<pre class="python"><code>torch.manual_seed(1)
#
x = torch.unsqueeze(torch.linspace(-1, 1, 100), dim = 1)
y = x.pow(2) + 0.2 * torch.rand(x.size())
#
x = Variable(x)
y = Variable(y)</code></pre>
<p>Then we can define the model class</p>
<pre class="python"><code>class Net(torch.nn.Module):
def __init__(self, n_feature, n_hidden, n_output):
super(Net, self).__init__()
self.hidden = torch.nn.Linear(n_feature, n_hidden)
self.predict = torch.nn.Linear(n_hidden, n_output)

def forward(self, x):
x = torch.nn.functional.relu(self.hidden(x))
x = self.predict(x)
return(x)</code></pre>
<p>We can create a model instance and construct the criterion and optimizer as follows</p>
<pre class="python"><code>myNet = Net(1, 20, 1)
criterion = torch.nn.MSELoss(size_average = True)
optimizer = torch.optim.SGD(myNet.parameters(), lr = 0.1) # torch.optim.Adam</code></pre>
<p>To train a model, we can rely on the gradient descent</p>
<pre class="python"><code>for epoch in range(500):
# make predictions
y_pred = myNet(x)
# calculate the loss
loss = criterion(y_pred, y)
# zero the gradient
optimizer.zero_grad()
# backpropagation
loss.backward()
# apply gradients
optimizer.step()
#
print(&quot;epoch {}, loss {}&quot;.format(epoch, loss.item()))</code></pre>
<p>Note one can also rely on the nn.Sequential module from PyTorch to construct the network</p>
<pre class="python"><code># 
net = torch.nn.Sequential(
torch.nn.Linear(1, 10),
torch.nn.ReLU(),
torch.nn.Linear(10, 10),
torch.nn.ReLU(),
torch.nn.Linear(10,1)
)
# </code></pre>
</div>
