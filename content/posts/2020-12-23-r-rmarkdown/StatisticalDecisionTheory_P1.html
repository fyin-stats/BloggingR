---
title: "A self-learning note for statistical decision theory - part 1"
author: "Fan Yin"
date: '2020-12-23T21:13:14-05:00'
output:
  html_notebook:
    mathjax: "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML.js"
categories: Statistics
tags:
- Statistical Decision Theory
- Bayesian Analysis
---



<p>As a statistician who often solves problems from a frequentist perspective but with a Bayesian soul (allegedly), statistical decision theory has always been an intriguing topic to me. Thanks to the holiday season, I finally got a chance to revisit this topic and I hope I can build up a more systematic understanding of it this time. To facilitate my mastery of the knowledge, I plan to learn by writing and sharing. As the very first step of this project, I’d like to cover the basic elements here in this blog post, including - (i) Motivation: what values can statistical decision theory offer? (ii) Notations and key concepts; (iii) Optimality criteria - how do we make decisions?</p>
<div id="motivation" class="section level2">
<h2>Motivation</h2>
<p>The statistical decision theory, as noted by Dr. James O. Berger in his book “Statistical Decision Theory and Bayesian Analysis”, is concerned with the problem of making decisions in the presence of statistical knowledge which can help explain some of the uncertainties involved in the decision-making problem. Typically, the uncertainties are assumed to be represented by unknown quantities (parameters) - for example, the proportion of people for which the drug will prove effective, <span class="math inline">\(\theta\)</span>, which is generally unknown, and one must conduct experiments to obtain statistical information about it. The classical statistics targets at making inference about the parameters based on the sample information only, whereas the statistical decision theory is aimed at combing the sample information with other relevant knowledge (including possible consequences associated with different decisions, a-priori knowledge about the possible values of parameters) to make the  decision.</p>
<!-- # ```{r cars} -->
<!-- # summary(cars) -->
<!-- # ``` -->
</div>
<div id="notations-and-key-concepts" class="section level2">
<h2>Notations and Key Concepts</h2>

<p>After observing the data <span class="math inline">\(X\)</span>, the decision-maker picks a decision that minimizes the loss <span class="math inline">\(L(\theta, a)\)</span>, for the unknown parameters <span class="math inline">\(\theta\)</span>. For example, the most commonly used loss functions are listed below</p>

<!-- You can also embed plots, for example: -->
<!-- ```{r pressure, echo=FALSE} -->
<!-- plot(pressure) -->
<!-- ``` -->
<!-- Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot. -->
</div>
